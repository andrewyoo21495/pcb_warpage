#!/usr/bin/env python3
"""PCB Warpage dataset for CVAE training.

Default directory layout (synthetic data generated by this project):
  data/
    design/
      design_A.png  design_B.png  design_C.png  design_D.png
    elevation/
      design_A/  design_B/  design_C/  design_D/

Custom layout — configure with these optional config.txt keys:
  design_names        A, B, C          # comma-separated names (no extension)
  design_image_dir    D:/my/designs    # folder that contains {name}.png files
  elevation_base_dir  D:/my/elev       # folder that contains {name}/ subfolders
  elevation_subdir    images           # subfolder INSIDE each {name}/ folder
                                       # (leave blank / omit if images are
                                       #  directly inside {name}/)

Example — if your data looks like:
  D:/path_to_elevation/
    A.png  B.png  C.png
    A/images/*.png
    B/images/*.png
    C/images/*.png

Set in config.txt:
  design_names        A, B, C
  design_image_dir    D:/path_to_elevation
  elevation_base_dir  D:/path_to_elevation
  elevation_subdir    images
  num_designs         3
  val_fold            0     # 0=A, 1=B, 2=C

Leave-one-out split:
  val_fold index  → design at that position in design_names is held out
  split='train'   → all designs except val_fold
  split='val'     → only val_fold design
"""

import random
from pathlib import Path

import torch
from torch.utils.data import Dataset
import torchvision.transforms.functional as TF
from PIL import Image

from utils.handcrafted_features import extract_handcrafted_features

# Default names used when 'design_names' is not set in config
_DEFAULT_DESIGN_NAMES = [
    'design_A', 'design_B', 'design_C', 'design_D',
    'design_E', 'design_F', 'design_G', 'design_H', 'design_I', 'design_J',
]


def _resolve_design_names(config: dict) -> list[str]:
    """Read design_names from config, or fall back to the default 4-design list."""
    raw = config.get('design_names', None)
    if raw is None:
        return list(_DEFAULT_DESIGN_NAMES)
    if isinstance(raw, list):
        return [str(n).strip() for n in raw]
    # single string — may be comma-separated already (load_config keeps commas as list)
    return [str(n).strip() for n in str(raw).split(',')]


class PCBWarpageDataset(Dataset):
    """Dataset of (design, elevation) image pairs for CVAE training.

    Args:
        dataset_dir : Root data directory (only used for default path resolution).
        config      : Config dict from load_config().
        split       : 'train' or 'val'.
        val_fold    : Index into design_names for the held-out design.
    """

    def __init__(self, dataset_dir: str, config: dict, split: str = 'train', val_fold: int = 0):
        super().__init__()
        self.image_size = int(config.get('image_size', 256))
        self.split      = split
        self.val_fold   = val_fold

        use_design_aug    = config.get('use_design_aug', True)
        use_elevation_aug = config.get('use_elevation_aug', True)
        self.augment           = (split == 'train')
        self.use_design_aug    = use_design_aug and self.augment
        self.use_elevation_aug = use_elevation_aug and self.augment

        # --- Resolve design names ---
        self.design_names = _resolve_design_names(config)

        # --- Resolve directory paths ---
        root = Path(dataset_dir)
        self.design_image_dir   = Path(config.get('design_image_dir',
                                                   str(root / 'design')))
        self.elevation_base_dir = Path(config.get('elevation_base_dir',
                                                   str(root / 'elevation')))
        self.elevation_subdir   = str(config.get('elevation_subdir', '')).strip()

        if val_fold >= len(self.design_names):
            raise ValueError(
                f"val_fold={val_fold} is out of range for "
                f"design_names={self.design_names} (len={len(self.design_names)})"
            )

        self.samples = self._build_sample_list()
        print(f"PCBWarpageDataset [{split}]: {len(self.samples)} samples "
              f"(val_fold={val_fold}, held-out='{self.design_names[val_fold]}')")

    # ------------------------------------------------------------------
    def _build_sample_list(self):
        """Return list of (design_path, elevation_path) tuples."""
        samples = []

        for idx, name in enumerate(self.design_names):
            is_val_design = (idx == self.val_fold)
            if self.split == 'train' and is_val_design:
                continue
            if self.split == 'val' and not is_val_design:
                continue

            design_path = self.design_image_dir / f"{name}.png"

            if self.elevation_subdir:
                elev_dir = self.elevation_base_dir / name / self.elevation_subdir
            else:
                elev_dir = self.elevation_base_dir / name

            if not design_path.exists():
                raise FileNotFoundError(f"Design image not found: {design_path}")
            if not elev_dir.exists():
                raise FileNotFoundError(f"Elevation directory not found: {elev_dir}")

            elev_paths = sorted(elev_dir.glob('*.png'))
            if len(elev_paths) == 0:
                raise ValueError(f"No PNG elevation images found in {elev_dir}")

            for elev_path in elev_paths:
                samples.append((str(design_path), str(elev_path)))

        return samples

    # ------------------------------------------------------------------
    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        design_path, elev_path = self.samples[idx]

        # Load grayscale PIL images at original resolution
        design_orig = Image.open(design_path).convert('L')
        elevation   = Image.open(elev_path).convert('L')

        # Extract handcrafted features at original resolution — before any resize.
        # Downsampling blurs thin design lines into grey, shifting the binary
        # threshold used for density and edge-ratio calculations.
        hand_features = extract_handcrafted_features(design_orig)

        # Resize to model input size
        size = (self.image_size, self.image_size)
        design    = design_orig.resize(size, Image.LANCZOS)
        elevation = elevation.resize(size, Image.LANCZOS)

        # --- Shared spatial augmentation (same transform applied to both) ---
        if self.augment:
            if random.random() > 0.5:
                design    = TF.hflip(design)
                elevation = TF.hflip(elevation)
            if random.random() > 0.5:
                design    = TF.vflip(design)
                elevation = TF.vflip(elevation)

        # --- Design-specific augmentation (brightness / contrast jitter) ---
        if self.use_design_aug:
            brightness_factor = random.uniform(0.7, 1.3)
            contrast_factor   = random.uniform(0.7, 1.3)
            design = TF.adjust_brightness(design, brightness_factor)
            design = TF.adjust_contrast(design, contrast_factor)

        # Convert to float tensors in [0, 1]  →  shape (1, H, W)
        design_tensor    = TF.to_tensor(design)    # white=1.0, black=0.0
        elevation_tensor = TF.to_tensor(elevation) # smooth values in [0, 1]

        return design_tensor, elevation_tensor, hand_features


def create_dataloaders(config: dict):
    """Create train and validation DataLoaders from config.

    Returns:
        train_loader, val_loader
    """
    from torch.utils.data import DataLoader

    dataset_dir  = config.get('dataset_dir', './data')
    val_fold     = int(config.get('val_fold', 0))
    batch_size   = int(config.get('batch_size', 32))
    num_workers  = int(config.get('num_workers', 4))

    train_dataset = PCBWarpageDataset(dataset_dir, config, split='train', val_fold=val_fold)
    val_dataset   = PCBWarpageDataset(dataset_dir, config, split='val',   val_fold=val_fold)

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True,
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )
    return train_loader, val_loader
